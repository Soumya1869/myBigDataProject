{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8c1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreaming\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\",\"true\") \\\n",
    "    .config(\"spark.jars.packeges\",\"org.apache.spark:spark-sql-kafka-0-10_2.13:3.1.2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "     .config(\"hive.metastore.uris\", \"thrift://your-hive-metastore-uri:port\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b045f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configs\n",
    "kafka_input_config = {\n",
    "    \"kafka.bootstrap.servers\": \"localhost:9092\",  # Adjust as necessary\n",
    "    \"subscribe\": \"fraudtraindata\",  # Your topic name\n",
    "    \"startingOffsets\": \"latest\",\n",
    "    \"failOnDataLoss\": \"false\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"trans_date_trans_time\", StringType(), True),\n",
    "    StructField(\"cc_num\", StringType(), True),\n",
    "    StructField(\"merchant\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"amt\", DoubleType(), True),\n",
    "    StructField(\"first\", StringType(), True),\n",
    "    StructField(\"last\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"zip\", StringType(), True),\n",
    "    StructField(\"lat\", DoubleType(), True),\n",
    "    StructField(\"long\", DoubleType(), True),\n",
    "    StructField(\"city_pop\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"dob\", StringType(), True),\n",
    "    StructField(\"trans_num\", StringType(), True),\n",
    "    StructField(\"unix_time\", LongType(), True),\n",
    "    StructField(\"merch_lat\", DoubleType(), True),\n",
    "    StructField(\"merch_long\", DoubleType(), True),\n",
    "    StructField(\"is_fraud\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a320984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiveInsert(df, epoch_id):\n",
    "        df.write.mode(\"append\").insertInto(\"fraud_detection.streamtransactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b90410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .options(**kafka_input_config) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_df = df.selectExpr(\"CAST(value AS STRING) as value\")\n",
    "\n",
    "json_df = value_df.withColumn(\"value\", from_json(col(\"value\"), schema))\n",
    "\n",
    "flattened_df = json_df.select(\"value.*\") \\\n",
    "    .withColumn(\"trans_date_trans_time\", to_timestamp(\"trans_date_trans_time\", \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .withColumn(\"cc_num\", col(\"cc_num\").cast(\"BIGINT\")) \\\n",
    "    .withColumn(\"amt\", col(\"amt\").cast(\"DECIMAL(20,15)\")) \\\n",
    "    .withColumn(\"lat\", col(\"lat\").cast(\"DECIMAL(9,6)\")) \\\n",
    "    .withColumn(\"long\", col(\"long\").cast(\"DECIMAL(9,6)\")) \\\n",
    "    .withColumn(\"merch_lat\", col(\"merch_lat\").cast(\"DECIMAL(20,13)\")) \\\n",
    "    .withColumn(\"merch_long\", col(\"merch_long\").cast(\"DECIMAL(20,13)\")) \\\n",
    "    .withColumn(\"dob\", col(\"dob\").cast(\"DATE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStream = flattened_df.writeStream \\\n",
    "    .foreachBatch(hiveInsert) \\\n",
    "    .option(\"checkpointLocation\", \"/Data/hive_checkpoint\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "myStream.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
